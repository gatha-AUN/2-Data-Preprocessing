{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/kanncaa1/feature-selection-and-data-visualization\n",
    "# https://towardsdatascience.com/feature-selection-techniques-1bfab5fe0784\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mushrooms = pd.read_csv(\"./datasets/mushrooms.csv\")\n",
    "print (\"Dataset shape: \", mushrooms.shape, \"\\n\")\n",
    "\n",
    "print(\"Top 5 rows in dataset:\")\n",
    "mushrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into attributes( = X) & output( = Y)\n",
    "# Then to train & test sets\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plot the distribution of two classes viz P(poisonous) & E(edible)\n",
    "Y = mushrooms['class']\n",
    "ax = sns.countplot(Y, label=\"Count\")\n",
    "Po, Ed = Y.value_counts()\n",
    "print('Number of edible mushrooms: ', Po)\n",
    "print('Number of poisonous mushrooms : ', Ed)\n",
    "\n",
    "X = mushrooms.drop(['class'], axis = 1)\n",
    "X = pd.get_dummies(X, prefix_sep='_')\n",
    "print (\"X shape: \", X.shape)\n",
    "\n",
    "# One hot encode categorical values\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "\n",
    "X2 = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Split into train-test sets\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X2, Y, test_size = 0.30, random_state = 101)\n",
    "\n",
    "print (\"Train set size (X): \", X_Train.shape)\n",
    "print (\"Test set size (X): \", X_Test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~ 1. Filter Method Contd.~~~~~~~~~\n",
    "# a) Correlation Matrix Analysis\n",
    "\n",
    "Numeric_df = pd.DataFrame(X)\n",
    "Numeric_df['Y'] = Y\n",
    "corr = Numeric_df.corr()\n",
    "corr_y = abs(corr[\"Y\"])\n",
    "\n",
    "# Considering the features that are at least 0.5 correlated with the output variable\n",
    "highest_corr = corr_y[corr_y > 0.5]\n",
    "highest_corr.sort_values(ascending = True)\n",
    "print (\"Features with correlation >= 0.5: \\n\", highest_corr, \"\\n\")\n",
    "\n",
    "# Plotting a Correlation Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "corr2 = Numeric_df[['bruises_f' , 'bruises_t' , 'gill-color_b' , 'gill-size_b' , \n",
    "                    'gill-size_n' , 'ring-type_p' , 'stalk-surface-below-ring_k' , \n",
    "                    'stalk-surface-above-ring_k' , 'odor_f', 'odor_n']].corr()\n",
    "\n",
    "sns.heatmap(corr2, annot=True, fmt=\".2g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features that are most correlated with Y\n",
    "# train/test an SVM model to evaluate the results of this approach\n",
    "X_Reduced2 = X[['bruises_f', 'bruises_t', 'gill-color_b', \n",
    "                'gill-size_b', 'gill-size_n', 'ring-type_p', \n",
    "                'stalk-surface-below-ring_k', 'stalk-surface-above-ring_k', \n",
    "                'odor_f', 'odor_n']]\n",
    "X_Reduced2 = StandardScaler().fit_transform(X_Reduced2)\n",
    "X_Train3, X_Test3, Y_Train3, Y_Test3 = train_test_split(X_Reduced2, Y, \n",
    "                                                        test_size = 0.30, \n",
    "                                                        random_state = 101)\n",
    "                                                        \n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "start = time.process_time()\n",
    "trainedsvm = svm.LinearSVC().fit(X_Train3, Y_Train3)\n",
    "print(\"Processing time(s): \", time.process_time() - start)\n",
    "\n",
    "predictionsvm = trainedsvm.predict(X_Test3)\n",
    "print(confusion_matrix(Y_Test3,predictionsvm))\n",
    "print(classification_report(Y_Test3,predictionsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~ 1. Filter Method Contd.~~~~~~~~~\n",
    "# b) Feature Importance Ranking\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "X_feat = X\n",
    "X_feat = mushrooms.drop(['class'], axis = 1)\n",
    "X_feat = pd.get_dummies(X_feat, prefix_sep='_')\n",
    "#print (\"X shape: \", X.shape, \"X_Train shape: \", X_Train.shape)\n",
    "\n",
    "trainedforest = RandomForestClassifier(n_estimators=700).fit(X_Train,Y_Train)\n",
    "\n",
    "figure(num = None, figsize=(20, 22), dpi=80, facecolor='w', edgecolor='k')\n",
    "feat_importances = pd.Series(trainedforest.feature_importances_, index = X_feat.columns)\n",
    "feat_importances.nlargest(7).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training random forest using original data\n",
    "print (\"\\n~~ Training model using all the provided features ~~\\n\")\n",
    "\n",
    "start = time.process_time()\n",
    "trainedforest = RandomForestClassifier(n_estimators=700).fit(X_Train,Y_Train)\n",
    "\n",
    "print(\"Processing time(s): \", time.process_time() - start)\n",
    "predictionforest = trainedforest.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test,predictionforest))\n",
    "print(classification_report(Y_Test,predictionforest))\n",
    "\n",
    "print (\"\\n~~ Training model using the top 4 features ~~\\n\")\n",
    "\n",
    "# Training our model using the top 4\n",
    "\n",
    "X_Ranked_feat = X[['odor_n', 'odor_f', 'gill-size_n', 'gill-size_b']]\n",
    "X_Ranked_feat = StandardScaler().fit_transform(X_Ranked_feat)\n",
    "X_Train2, X_Test2, Y_Train2, Y_Test2 = train_test_split(X_Ranked_feat, Y, test_size = 0.30, \n",
    "                                                        random_state = 101)\n",
    "\n",
    "start = time.process_time()\n",
    "trainedforest = RandomForestClassifier(n_estimators = 700).fit(X_Train2, Y_Train2)\n",
    "print(\"Processing time(s): \", time.process_time() - start)\n",
    "predictionforest = trainedforest.predict(X_Test2)\n",
    "print(confusion_matrix(Y_Test2,predictionforest))\n",
    "print(classification_report(Y_Test2,predictionforest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~ 1. Filter Method Contd.~~~~~~~~~\n",
    "# c) Feature Importance Ranking \n",
    "# Using a trained decision tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_TreeTrain, X_TreeTest, Y_TreeTrain, Y_TreeTest = train_test_split(X, Y, test_size = 0.30, random_state = 101)\n",
    "\n",
    "start = time.process_time()\n",
    "trainedtree = tree.DecisionTreeClassifier().fit(X_TreeTrain, Y_TreeTrain)\n",
    "print(time.process_time() - start)\n",
    "predictionstree = trainedtree.predict(X_TreeTest)\n",
    "print(confusion_matrix(Y_TreeTest, predictionstree))\n",
    "print(classification_report(Y_TreeTest, predictionstree))\n",
    "\n",
    "import graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "data = export_graphviz(trainedtree,out_file=None,feature_names= X.columns,\n",
    "                       class_names=['edible', 'poisonous'],  \n",
    "                       filled=True, rounded=True,  \n",
    "                       max_depth=2,\n",
    "                       special_characters=True)\n",
    "graph = graphviz.Source(data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~ 2. Wrapper Method ~~~~~~~~~\n",
    "# Recursive Feature Elimination (RFE)\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "# More info at: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=700)\n",
    "num_features = 6\n",
    "\n",
    "rfe = RFE(model, num_features)\n",
    "# model =  estimator used, num_features = no. of features to select, step = 1(default)\n",
    "\n",
    "start = time.process_time()\n",
    "RFE_X_Train = rfe.fit_transform(X_Train,Y_Train)\n",
    "RFE_X_Test = rfe.transform(X_Test)\n",
    "rfe = rfe.fit(RFE_X_Train,Y_Train)\n",
    "print(\"Processing time(s): \", time.process_time() - start)\n",
    "print(\"Overall Accuracy using RFE: \", rfe.score(RFE_X_Test, Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~ 3. Embedded Method ~~~~~~~~~\n",
    "# Lasso (L1) Regression\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "X_LTrain, X_LTest, Y_LTrain, Y_LTest = train_test_split(X, Y, test_size = 0.30, random_state = 101)\n",
    "\n",
    "regr = LassoCV(cv = 5, random_state = 101)\n",
    "regr.fit(X_LTrain, Y_LTrain)\n",
    "\n",
    "print(\"LassoCV Best Alpha Scored: \", regr.alpha_)\n",
    "print(\"LassoCV Model Accuracy: \", regr.score(X_LTest, Y_LTest))\n",
    "\n",
    "indcs = list(X.columns[:])\n",
    "model_coef = pd.Series(regr.coef_, index = indcs)\n",
    "print(\"Variables Eliminated: \", str(sum(model_coef == 0)))\n",
    "print(\"Variables Kept: \", str(sum(model_coef != 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
